# í•´ì•¼í•˜ëŠ” ì‘ì—…
# ê° ë‚ ì§œì— ë§ê²Œ ë²¡í„° í•©ì„±(khoa+hycom)íŒŒì¼ ì´ë¦„ ì„¤ì •í•˜ê²Œ ìë™í™”
# OI ì ìš© ì™„ë£Œ í•œ íŒŒì¼ë˜í•œ ì´ë¦„ ìë™ ì €ì¥í•˜ê²Œ ìë™í™”


import os
import requests
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter
from matplotlib.widgets import Slider
from matplotlib.colors import Normalize
import pandas as pd
import json
from datetime import datetime

# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================


SERVICE_KEY = "ANM8LV6zTsRNiGg6FCUMpw=="



# 2ï¸âƒ£ ì°¾ê³  ì‹¶ì€ ìœ„ê²½ë„ ë²”ìœ„ ì„¤ì • (ì—¬ê¸°ë§Œ ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ìˆ˜ì •!)
MIN_X = 123.9609466
MAX_X = 129.22982499999998
MIN_Y = 31.82632165
MAX_Y = 35.986358300000006



data1 = [
    ["TW_0088","ê°ì²œí•­",35.052,129.003],
    ["TW_0077","ê²½ì¸í•­",37.523,126.592],
    ["TW_0089","ê²½í¬ëŒ€í•´ìˆ˜ìš•ì¥",37.808,128.931],
    ["TW_0095","ê³ ë˜ë¶ˆí•´ìˆ˜ìš•ì¥",36.58,129.454],
    ["TW_0074","ê´‘ì–‘í•­",34.859,127.792],
    ["TW_0072","êµ°ì‚°í•­",35.984,126.508],
    ["TW_0091","ë‚™ì‚°í•´ìˆ˜ìš•ì¥",38.122,128.65],
    ["KG_0025","ë‚¨í•´ë™ë¶€",34.222,128.419],
    ["TW_0069","ëŒ€ì²œí•´ìˆ˜ìš•ì¥",36.274,126.457],
    ["KG_0024","ëŒ€í•œí•´í˜‘",34.919,129.121],
    ["TW_0085","ë§ˆì‚°í•­",35.103,128.631],
    ["TW_0094","ë§ìƒí•´ìˆ˜ìš•ì¥",37.616,129.103],
    ["TW_0087","ë¶€ì‚°í•­",35.091,129.085],
    ["TW_0086","ë¶€ì‚°í•­ì‹ í•­",35.043,128.761],
    ["TW_0079","ìƒì™•ë“±ë„",35.652,126.194],
    ["TW_0081","ìƒì¼ë„",34.258,126.96],
    ["TW_0093","ì†ì´ˆí•´ìˆ˜ìš•ì¥",38.198,128.631],
    ["TW_0090","ì†¡ì •í•´ìˆ˜ìš•ì¥",35.164,129.219],
    ["TW_0083","ì—¬ìˆ˜í•­",34.794,127.808],
    ["TW_0078","ì™„ë„í•­",34.325,126.763],
    ["TW_0080","ìš°ì´ë„",34.543,125.802],
    ["KG_0101","ìš¸ë¦‰ë„ë¶ë™",38.007,131.552],
    ["KG_0102","ìš¸ë¦‰ë„ë¶ì„œ",37.742,130.601],
    ["TW_0076","ì¸ì²œí•­",37.389,126.533],
    ["TW_0092","ì„ë‘í•´ìˆ˜ìš•ì¥",35.302,129.292],
    ["KG_0021","ì œì£¼ë‚¨ë¶€",32.09,126.965],
    ["KG_0028","ì œì£¼í•´í˜‘",33.7,126.59],
    ["TW_0075","ì¤‘ë¬¸í•´ìˆ˜ìš•ì¥",33.234,126.409],
    ["TW_0082","íƒœì•ˆí•­",37.006,126.27],
    ["TW_0084","í†µì˜í•­",34.773,128.46],
    ["TW_0062","í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥",35.148,129.17]
]
data2 = [
    ["HF_0064","ê´‘ì–‘í•­",34.887,127.797],
    ["HF_0076","êµ°ì‚°í•­",35.99,126.358],
    ["HF_0041","ëŒ€í•œí•´í˜‘",34.909,129.2],
    ["HF_0073","ë™í•´ë‚¨ë¶€",36.633,130.224],
    ["HF_0075","ëª©í¬í•­ë‚´ì¸¡",34.756,126.336],
    ["HF_0074","ëª©í¬í•­ì™¸ì¸¡",34.772,126.239],
    ["HF_0040","ë¶€ì‚°í•­ì‹ í•­",35.036,128.768],
    ["HF_0065","ì—¬ìˆ˜ê´‘ì–‘í•­",34.765,127.804],
    ["HF_0039","ì—¬ìˆ˜í•´ë§Œ",34.656,127.964],
    ["HF_0063","ìš¸ì‚°í•­",35.4,129.607],
    ["HF_0069","ì¸ì²œí•­",37.355,126.508],
    ["HF_0070","íƒœì•ˆëŒ€ì‚°",37.073,126.292],
    ["HF_0071","í¬í•­í•­",36.066,129.475]
]

# ì˜ˆ: r"D:\my_data\fix_range_hycon_data"
HYCOM_FOLDER_PATH = r"C:\Users\HUFS\Desktop\opendrift_middle\fix_range_hycom_data" 

# ì²˜ë¦¬í•  JSON íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
JSON_FOLDER_PATH = r"D:\ì–´ì„ í–‰ì ë°ì´í„°\Training\02.ë¼ë²¨ë§ë°ì´í„°\TL_01.ìë§.zip"

# ìµœì¢… ê²°ê³¼ë¬¼ì„ ì €ì¥í•  ê¸°ë³¸ í´ë” ê²½ë¡œ
BASE_OUTPUT_FOLDER_PATH = r'D:\current_oi\BASE_OUTPUT_FOLDER'

# ê° API ë°ì´í„°ë¥¼ ì €ì¥í•  í•˜ìœ„ í´ë” ê²½ë¡œ ì„¤ì •
BUOY_OUTPUT_FOLDER_PATH = os.path.join(BASE_OUTPUT_FOLDER_PATH, 'buoy_data')
HFRADAR_OUTPUT_FOLDER_PATH = os.path.join(BASE_OUTPUT_FOLDER_PATH, 'hfradar_data')



# ê²°ê³¼ë¬¼ ì €ì¥ í´ë”ë“¤ì´ ì—†ìœ¼ë©´ ëª¨ë‘ ìƒì„±
os.makedirs(BUOY_OUTPUT_FOLDER_PATH, exist_ok=True)
os.makedirs(HFRADAR_OUTPUT_FOLDER_PATH, exist_ok=True)


# ==============================================================================
# 2. JSON íŒŒì¼ ì‹œê°„ ì¶”ì¶œ í•¨ìˆ˜ (ì‹¤ì œ íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
# ==============================================================================
def extract_time_from_json(json_file_path):
    """
    JSON íŒŒì¼ì„ ì½ì–´ ì‹œì‘ê³¼ ë ì‹œê°„ ì •ë³´ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            # [ìˆ˜ì •ë¨] ë³´ë‚´ì£¼ì‹  JSON êµ¬ì¡°ì— ë§ê²Œ 'crs' ê°ì²´ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
            crs_data = data.get('crs', {})
            start_date_str = crs_data.get('start_time') # "2022-03-12 05:09:00"
            end_date_str = crs_data.get('end_time')     # "2022-03-13 05:08:00"
            
            if not all([start_date_str, end_date_str]):
                print(f"  - âŒ ì˜¤ë¥˜: JSON íŒŒì¼ì—ì„œ 'start_time' ë˜ëŠ” 'end_time'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None

            # [ìˆ˜ì •ë¨] ë‚ ì§œ ë¬¸ìì—´ í˜•ì‹ì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ datetime ê°ì²´ ë³€í™˜
            date_format = "%Y-%m-%d %H:%M:%S"
            start_date = datetime.strptime(start_date_str, date_format)
            end_date = datetime.strptime(end_date_str, date_format)
            
            return start_date, end_date

    except json.JSONDecodeError:
        print(f"  - âŒ ì˜¤ë¥˜: '{os.path.basename(json_file_path)}'ëŠ” ì˜¬ë°”ë¥¸ JSON íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return None, None
    except Exception as e:
        print(f"  - âŒ '{os.path.basename(json_file_path)}' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, None




# ==============================================================================
# ğŸ” 3. ë©”ì¸ ì²˜ë¦¬ ë¡œì§
# ==============================================================================

print(f"HYCOM í´ë”({HYCOM_FOLDER_PATH})ì—ì„œ íŒŒì¼ ëª©ë¡ì„ ì½ì–´ì˜µë‹ˆë‹¤...")
try:
    hycom_files = os.listdir(HYCOM_FOLDER_PATH)
    # íŒŒì¼ ì´ë¦„ì´ '..._hycom'ìœ¼ë¡œ ëë‚œë‹¤ê³  ê°€ì •í•˜ê³ , ê·¸ ì•ë¶€ë¶„(base_name)ì„ ì¶”ì¶œ
    # ì˜ˆ: 'T01_..._hycom' -> 'T01_...'
    hycom_base_names = set(f.rsplit('_', 1)[0] for f in hycom_files if '_hycom' in f)
    
    if not hycom_base_names:
        print(f"âš ï¸ ê²½ê³ : {HYCOM_FOLDER_PATH}ì—ì„œ '_hycom'ìœ¼ë¡œ ëë‚˜ëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        exit()
        
    print(f"ì´ {len(hycom_base_names)}ê°œì˜ HYCOM ê¸°ì¤€ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"âŒ ì˜¤ë¥˜: HYCOM í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {HYCOM_FOLDER_PATH}")
    print("ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ HYCOM_FOLDER_PATH ë³€ìˆ˜ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    exit()
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: HYCOM í´ë”ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()


print(f"ê³ ì • ìœ„ê²½ë„ ë²”ìœ„: LON({MIN_X}~{MAX_X}), LAT({MIN_Y}~{MAX_Y})")


# [ìˆ˜ì •ë¨] HYCOM íŒŒì¼ ëª©ë¡(hycom_base_names)ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì—… ë°˜ë³µ
for base_name in hycom_base_names:
    
    # [ìˆ˜ì •ë¨] ê¸°ì¤€ì´ ë˜ëŠ” base_nameìœ¼ë¡œë¶€í„° geojson íŒŒì¼ ì´ë¦„ê³¼ ì „ì²´ ê²½ë¡œ ìƒì„±
    geojson_filename = f"{base_name}.geojson"
    json_file_full_path = os.path.join(JSON_FOLDER_PATH, geojson_filename)
    
    print(f"\n{'='*80}\nâ–¶ï¸ ì‘ì—… ì‹œì‘: {geojson_filename}\n{'='*80}")

    # [ì‹ ê·œ ì¶”ê°€] í•´ë‹¹ geojson íŒŒì¼ì´ JSON_FOLDER_PATHì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(json_file_full_path):
        print(f"  - âš ï¸ ê²½ê³ : {geojson_filename} íŒŒì¼ì´ {JSON_FOLDER_PATH}ì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°

    # 1. JSONì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
    START_DATE, END_DATE = extract_time_from_json(json_file_full_path)

    if START_DATE is None:
        print(f"âš ï¸ ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ë¡œ '{geojson_filename}' íŒŒì¼ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        continue # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°

    print(f"  - ì¶”ì¶œëœ ê¸°ê°„: {START_DATE} ~ {END_DATE}")
    
    base_json_name = os.path.splitext(geojson_filename)[0]
    khoa_buoy_OUTPUT_FILENAME = os.path.join(BUOY_OUTPUT_FOLDER_PATH, f"{base_json_name}_buoy.nc")
    khoa_hfradar_output_filename = os.path.join(HFRADAR_OUTPUT_FOLDER_PATH, f"{base_json_name}_hfradar.nc")


    ########################################################
    # í•´ìƒë¶€ì´, ê´€ì¸¡ì†Œ api ëŒê³ ì˜¤ê¸°
    ########################################################


    # ë°ì´í„° í•„í„°ë§ ë° STATIONS ë”•ì…”ë„ˆë¦¬ ìƒì„±
    STATIONS1 = {}
    for item in data1:
        # item: [ID, Name, Latitude (Y), Longitude (X)]
        station_id, name, lat, lon = item[0], item[1], item[2], item[3]

        # ê²½ë„ (lon)ì™€ ìœ„ë„ (lat)ê°€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        is_in_x_range = MIN_X <= lon <= MAX_X
        is_in_y_range = MIN_Y <= lat <= MAX_Y
        
        if is_in_x_range and is_in_y_range:
            STATIONS1[station_id] = {
                'name': name,
                'lat': lat,
                'lon': lon
            }


    # ë°ì´í„° í•„í„°ë§ ë° STATIONS ë”•ì…”ë„ˆë¦¬ ìƒì„±
    STATIONS2 = {}
    for item in data2:
        # item: [ID, Name, Latitude (Y), Longitude (X)]
        station_id, name, lat, lon = item[0], item[1], item[2], item[3]

        # ê²½ë„ (lon)ì™€ ìœ„ë„ (lat)ê°€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        is_in_x_range = MIN_X <= lon <= MAX_X
        is_in_y_range = MIN_Y <= lat <= MAX_Y
        
        if is_in_x_range and is_in_y_range:
            STATIONS2[station_id] = {
                'name': name,
                'lat': lat,
                'lon': lon
            }


    from datetime import datetime, timedelta

    # ==============================================================================
    # ì„¤ì • ë¶€ë¶„ // ìœ„ê²½ë„ì— ë§ê²Œ ë²”ìœ„ ë‚´ì— ìˆëŠ” ê´€ì¸¡ì†Œì™€ í•´ìƒë¶€ì´ api ëŒê³ ì˜¤ê¸°
    # ==============================================================================


    # API ê¸°ë³¸ URL
    BUOY_BASE_URL  = "http://www.khoa.go.kr/api/oceangrid/tidalBu/search.do"





    # ==============================================================================
    # í•´ìƒë¶€ìœ„ ë¡œì§
    # ==============================================================================

    if os.path.exists(khoa_buoy_OUTPUT_FILENAME):
        print(f"ğŸ”„ ì´ë¯¸ NetCDF íŒŒì¼ì´ ì¡´ì¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ìƒëµí•©ë‹ˆë‹¤: {khoa_buoy_OUTPUT_FILENAME}")
    else:
        all_records = []
        
        # APIëŠ” í•˜ë£¨ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ì œê³µí•˜ë¯€ë¡œ, ë‚ ì§œ ëª©ë¡ ìƒì„±
        date_list = pd.date_range(start=START_DATE.date(), end=END_DATE.date()).tolist()

        # ====== API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘ ======
        for station_id, station_info in STATIONS1.items():
            for search_date in date_list:
                print(f"ğŸ“¡ {station_info['name']}({station_id}) ê´€ì¸¡ì†Œì˜ {search_date.strftime('%Y-%m-%d')} ë°ì´í„° ìš”ì²­ ì¤‘...")
                
                params = {
                    'ServiceKey': SERVICE_KEY,
                    'ObsCode': station_id,
                    'Date': search_date.strftime('%Y%m%d'),
                    'ResultType': 'json'
                }
                
                try:
                    response = requests.get(BUOY_BASE_URL , params=params, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        # ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                        if 'result' in data and 'data' in data['result']:
                            for record in data['result']['data']:
                                all_records.append({
                                    'station_id': station_id,
                                    'station_name': station_info['name'],
                                    'lat': station_info['lat'],
                                    'lon': station_info['lon'],
                                    'time': pd.to_datetime(record['obs_time']),
                                    'current_speed_cm_s': pd.to_numeric(record['current_speed'], errors='coerce'),
                                    'current_direction_deg': pd.to_numeric(record['current_direct'], errors='coerce')
                                })
                        else:
                            print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ: {station_info['name']} ({search_date.strftime('%Y-%m-%d')})")

                    else:
                        print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {station_info['name']}, Status Code: {response.status_code}")

                except requests.exceptions.RequestException as e:
                    print(f"   âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {station_info['name']}, {e}")
                except Exception as e:
                    print(f"   âŒ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {station_info['name']}, {e}")
        
        if not all_records:
            print("ğŸ˜­ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ NetCDF íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue  # ğŸš¨ ë‹¤ìŒ JSON íŒŒì¼ë¡œ ë°”ë¡œ ë„˜ì–´ê°€ê¸°
        else:
            # ====== ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° í•„í„°ë§ ======
            df = pd.DataFrame(all_records)
            df.dropna(inplace=True) # ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°

            # ì‹œê°„ ë²”ìœ„ ë° ì •ê° ë°ì´í„° í•„í„°ë§
            df_hourly = df[
                (df['time'] >= START_DATE) & 
                (df['time'] <= END_DATE) & 
                (df['time'].dt.minute == 0)
            ].copy()

            print(f"\nğŸ“Š ì´ {len(df_hourly)}ê°œì˜ ì‹œê°„ë³„ ê´€ì¸¡ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.")

            # ====== NetCDF ìƒì„± ======
            # xarrayê°€ ì¸ì‹í•˜ê¸° ì¢‹ê²Œ station_idë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
            df_hourly.drop_duplicates(subset=['station_id', 'time'], inplace=True, keep='first')

            # ë¬¸ìì—´ ë³€ìˆ˜(station_name)ë¥¼ ë°”ì´íŠ¸í˜•ìœ¼ë¡œ ë³€í™˜ (NetCDF ì €ì¥ ê°€ëŠ¥í•˜ë„ë¡)
            df_hourly["station_name"] = df_hourly["station_name"].astype(str).apply(lambda x: x.encode("utf-8"))

            # ì´ì œ ì¤‘ë³µì´ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            df_hourly.set_index(['station_id', 'time'], inplace=True)
            ds = df_hourly.to_xarray()
            
            # ê° ë³€ìˆ˜ì— ëŒ€í•œ ì†ì„±(ì„¤ëª…, ë‹¨ìœ„) ì¶”ê°€
            ds['station_name'].attrs = {'long_name': 'Observation station name'}
            ds['lat'].attrs = {'long_name': 'Latitude', 'units': 'degrees_north'}
            ds['lon'].attrs = {'long_name': 'Longitude', 'units': 'degrees_east'}
            ds['current_speed_cm_s'].attrs = {'long_name': 'Sea water speed', 'units': 'cm/s'}
            ds['current_direction_deg'].attrs = {'long_name': 'Sea water direction (from north)', 'units': 'degree'}

            # íŒŒì¼ ì „ì²´ì— ëŒ€í•œ ì „ì—­ ì†ì„± ì¶”ê°€
            ds.attrs = {
                'title': 'KHOA Oceanographic Buoy Data',
                'source': 'Korea Hydrographic and Oceanographic Agency (KHOA)',
                'api': 'tidalBu (í•´ì–‘ê´€ì¸¡ë¶€ì´)',
                'description': 'Hourly current speed and direction data from KHOA buoys.',
                'history': f'Created on {datetime.now().isoformat()}'
            }
            
            # NetCDF íŒŒì¼ë¡œ ì €ì¥
            ds.to_netcdf(khoa_buoy_OUTPUT_FILENAME)
            print(f"\nâœ… NetCDF íŒŒì¼ ìƒì„± ì™„ë£Œ: {khoa_buoy_OUTPUT_FILENAME}")
            
            
    # ==============================================================================
    # í•´ìƒ ê´€ì¸¡ì†Œ ë¡œì§
    # ==============================================================================        
            
    # HF-RADAR API ê¸°ë³¸ ì •ë³´
    HFRADAR_BASE_URL = "http://www.khoa.go.kr/api/oceangrid/tidalHfRadar/search.do"

    START_DATE = START_DATE.replace(minute=0, second=0, microsecond=0)
    END_DATE = END_DATE.replace(minute=0, second=0, microsecond=0)
    # ë°ì´í„° ì¡°íšŒ ê¸°ê°„ ì„¤ì • (ì´ì „ê³¼ ë™ì¼)
    time_list = pd.date_range(start=START_DATE, end=END_DATE, freq='H')


    # ==================================
    # 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬
    # ==================================
    if os.path.exists(khoa_hfradar_output_filename):
        print(f"ğŸ”„ ì´ë¯¸ NetCDF íŒŒì¼ì´ ì¡´ì¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ìƒëµí•©ë‹ˆë‹¤: {khoa_hfradar_output_filename}")
    else:
        all_records = []

        print("ğŸš€ HF-RADAR API ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        # ëª¨ë“  ê´€ì¸¡ì†Œì™€ ì‹œê°„ì— ëŒ€í•´ API í˜¸ì¶œ
        for obs_code, station_name in STATIONS2.items():
            for t in time_list:
                # Date íŒŒë¼ë¯¸í„° í˜•ì‹ì´ YYYYMMDDHH ì…ë‹ˆë‹¤.
                date_str = t.strftime("%Y%m%d%H")
                
                params = {
                    'ServiceKey': SERVICE_KEY,
                    'ObsCode': obs_code,
                    'Date': date_str,
                    'ResultType': 'json'
                }
                
                try:
                    response = requests.get(HFRADAR_BASE_URL, params=params)
                    if response.status_code == 200:
                        data = response.json()
                        # 'data' í‚¤ê°€ ìˆëŠ”ì§€, ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                        if 'result' in data and 'data' in data['result'] and data['result']['data']:
                            # í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì—¬ëŸ¬ ìœ„ì¹˜ì˜ ë°ì´í„°ê°€ ë“¤ì–´ì˜´
                            for record in data['result']['data']:
                                all_records.append({
                                    'time': t,
                                    'station_id': obs_code,
                                    'station_name': station_name,
                                    'lat': float(record.get('lat', float('nan'))),
                                    'lon': float(record.get('lon', float('nan'))),
                                    'current_speed': float(record.get('current_speed', float('nan'))), # cm/s
                                    'current_direct': float(record.get('current_direct', float('nan'))) # deg
                                })
                            print(f"âœ… [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
                        else:
                            print(f"âš ï¸ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} API í˜¸ì¶œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
                except requests.exceptions.RequestException as e:
                    print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ìš”ì²­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                except ValueError: # JSON ë””ì½”ë”© ì˜¤ë¥˜ ì²˜ë¦¬
                    print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ ë‚´ìš©: {response.text}")


        if not all_records:
            print("ğŸ˜­ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ NetCDF íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue  # ğŸš¨ ë‹¤ìŒ JSON íŒŒì¼ë¡œ ë„˜ì–´ê°€ê¸°
        else:
            # ==================================
            # 3. NetCDF ìƒì„±
            # ==================================
            print("\nğŸ“Š NetCDF íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
            
            df = pd.DataFrame(all_records)
            # ì¤‘ë³µ ë°ì´í„° ì œê±° (ì•ˆì •ì„± í™•ë³´)
            df.drop_duplicates(subset=['time', 'lat', 'lon'], inplace=True, keep='first')
            

                # âœ… ë¬¸ìì—´ì„ ë°”ì´íŠ¸í˜•ìœ¼ë¡œ ë³€í™˜ (NetCDF ì €ì¥ ê°€ëŠ¥í•˜ë„ë¡)
            df["station_name"] = df["station_name"].astype(str).apply(lambda x: x.encode("utf-8"))
            # ë°ì´í„°í”„ë ˆì„ì„ xarray Datasetìœ¼ë¡œ ë³€í™˜
            # HF-Radar ë°ì´í„°ëŠ” ê° ì‹œê°„ì´ ê³µê°„ ê²©ìë¥¼ ê°€ì§€ë¯€ë¡œ, ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
            ds = df.set_index('time').to_xarray()
            
            # ë³€ìˆ˜ ì†ì„±(metadata) ì¶”ê°€
            ds['current_speed'].attrs = {'long_name': 'Sea Water Speed', 'units': 'cm/s'}
            ds['current_direct'].attrs = {'long_name': 'Sea Water To Direction', 'units': 'degree'}
            ds['lat'].attrs = {'units': 'degrees_north'}
            ds['lon'].attrs = {'units': 'degrees_east'}
            ds['station_id'].attrs = {'long_name': 'Observation station code'}
            
            # ì „ì—­ ì†ì„±(Global attributes) ì¶”ê°€
            ds.attrs = {
                'title': 'KHOA HF-RADAR Ocean Current Data',
                'source': 'Korea Hydrographic and Oceanographic Agency (KHOA)',
                'api_url': 'http://www.khoa.go.kr/api/oceangrid/tidalHfRadar/search.do',
                'history': f'Created on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
            }

            # NetCDF íŒŒì¼ë¡œ ì €ì¥
            ds.to_netcdf(khoa_hfradar_output_filename)
            print(f"âœ… NetCDF ìƒì„± ì™„ë£Œ: {khoa_hfradar_output_filename}")
            
            
        print(f"\nğŸ‰ {geojson_filename}ì— ëŒ€í•œ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

print(f"\n{'='*80}\nâœ… ëª¨ë“  GeoJSON íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n{'='*80}")
        