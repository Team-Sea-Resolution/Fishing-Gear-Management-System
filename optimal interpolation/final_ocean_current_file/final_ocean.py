# í•´ì•¼í•˜ëŠ” ì‘ì—…
# ê° ë‚ ì§œì— ë§ê²Œ ë²¡í„° í•©ì„±(khoa+hycom)íŒŒì¼ ì´ë¦„ ì„¤ì •í•˜ê²Œ ìë™í™”
# OI ì ìš© ì™„ë£Œ í•œ íŒŒì¼ë˜í•œ ì´ë¦„ ìë™ ì €ì¥í•˜ê²Œ ìë™í™”


import os
import requests
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter
from matplotlib.widgets import Slider
from matplotlib.colors import Normalize
import pandas as pd

# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================


SERVICE_KEY = "ANM8LV6zTsRNiGg6FCUMpw=="
# ë°ì´í„° ì¡°íšŒ ê¸°ê°„ ì„¤ì •
START_DATE = datetime(2021, 11, 1, 0, 0)
END_DATE = datetime(2021, 11, 2, 23, 0)

# 2ï¸âƒ£ ì°¾ê³  ì‹¶ì€ ìœ„ê²½ë„ ë²”ìœ„ ì„¤ì • (ì—¬ê¸°ë§Œ ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ìˆ˜ì •!)
MIN_X = 123.9609466
MAX_X = 129.22982499999998
MIN_Y = 31.82632165
MAX_Y = 35.986358300000006



# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================

########################################################
# hycom, khoa ë²¡í„°ë°ì´í„° í•©ì¹˜ê¸°
########################################################


# ---------------------------
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------
hycom_file = r"C:\Users\USER\Desktop\ocean_data_develop\ncfile\hycom_data.nc4" # hycom data ê²½ë¡œ
khoa_file  = r"C:\Users\USER\Desktop\ocean_data_develop\ncfile\khoa_nc_data_uv.nc" # khoa data ê²½ë¡œ


ds_hycom = xr.open_dataset(hycom_file)
ds_khoa  = xr.open_dataset(khoa_file)

# ---------------------------
# 2. ì‹œê°„ê³¼ ì¢Œí‘œ ë§ì¶”ê¸°
# ---------------------------
lat_khoa = ds_khoa['lat']
lon_khoa = ds_khoa['lon']
time_khoa = ds_khoa['time']

# HYCOM í‘œì¸µë§Œ ì„ íƒ
u_hycom = ds_hycom['water_u'].isel(depth=0)
v_hycom = ds_hycom['water_v'].isel(depth=0)

# ì‹œê°„ + ì¢Œí‘œ ë³´ê°„
u_hycom_interp = u_hycom.interp(time=time_khoa, lat=lat_khoa, lon=lon_khoa)
v_hycom_interp = v_hycom.interp(time=time_khoa, lat=lat_khoa, lon=lon_khoa)

# KHOA ì†ë„
u_khoa = ds_khoa['eastward_sea_water_velocity']
v_khoa = ds_khoa['northward_sea_water_velocity']

# ---------------------------
# 3. ë²¡í„° í•©ì„±
# ---------------------------
w_hycom = 0.5
w_khoa  = 0.5

u_combined = w_hycom * u_hycom_interp + w_khoa * u_khoa
v_combined = w_hycom * v_hycom_interp + w_khoa * v_khoa
speed_combined = np.sqrt(u_combined**2 + v_combined**2)

# ---------------------------
# 4. ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯
# ---------------------------
fig, ax = plt.subplots(figsize=(10,8))
plt.subplots_adjust(bottom=0.2)

# ì»¬ëŸ¬ë§µ ë²”ìœ„ ê³ ì •
vmin = float(speed_combined.min())
vmax = float(speed_combined.max())
norm = Normalize(vmin=vmin, vmax=vmax)

# ì´ˆê¸° í”„ë ˆì„
frame0 = 0
mesh = ax.pcolormesh(lon_khoa, lat_khoa, speed_combined.isel(time=frame0),
                     cmap='viridis', norm=norm)
q = ax.quiver(lon_khoa[::5], lat_khoa[::5],
              u_combined.isel(time=frame0)[::5, ::5],
              v_combined.isel(time=frame0)[::5, ::5],
              scale=5, color='k')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.set_title(f'Combined Currents at {str(time_khoa[frame0].values)}')
cbar = fig.colorbar(mesh, ax=ax, label='Current speed (m/s)')

# ---------------------------
# 5. ì‹œê°„ ìŠ¬ë¼ì´ë” ì¶”ê°€
# ---------------------------
ax_slider = plt.axes([0.15, 0.05, 0.7, 0.03])
slider = Slider(ax_slider, 'Time', 0, len(time_khoa)-1, valinit=frame0, valstep=1)

def update(val):
    frame = int(slider.val)
    mesh.set_array(speed_combined.isel(time=frame).values.ravel())
    q.set_UVC(u_combined.isel(time=frame)[::5, ::5].values,
              v_combined.isel(time=frame)[::5, ::5].values)
    ax.set_title(f'Combined Currents at {str(time_khoa[frame].values)}')
    fig.canvas.draw_idle()

slider.on_changed(update)
plt.show()


# ====================================================================================================
import xarray as xr
import numpy as np

# ---------------------------
# 1. í•©ì„± ë°ì´í„° ì¤€ë¹„
# ---------------------------
# u_combined, v_combined, speed_combined
# lat_khoa, lon_khoa, time_khoa ì´ë¯¸ ì¡´ì¬

# DataArray â†’ ndarrayë¡œ ë³€í™˜
u_data = u_combined.data
v_data = v_combined.data
speed_data = speed_combined.data

# ìƒˆë¡œìš´ xarray.Dataset ìƒì„±
ds_combined = xr.Dataset(
    {
        "eastward_velocity": (["time", "lat", "lon"], u_data),
        "northward_velocity": (["time", "lat", "lon"], v_data),
        "speed": (["time", "lat", "lon"], speed_data)
    },
    coords={
        "time": time_khoa.data,
        "lat": lat_khoa.data,
        "lon": lon_khoa.data
    },
    attrs={
        "title": "Combined HYCOM + KHOA currents",
        "source": "HYCOM (0.5) + KHOA (0.5)",
        "description": "Eastward/northward velocities and speed",
        "Conventions": "CF-1.6"
    }
)

# ---------------------------
# 2. NetCDF íŒŒì¼ ì €ì¥
# ---------------------------
output_file = "combined_currents.nc"
ds_combined.to_netcdf(output_file)

print(f"âœ… Combined NetCDF file saved as: {output_file}")


# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================


########################################################
# í•´ìƒë¶€ì´, ê´€ì¸¡ì†Œ api ëŒê³ ì˜¤ê¸°
########################################################

data1 = [
    ["TW_0088","ê°ì²œí•­",35.052,129.003],
    ["TW_0077","ê²½ì¸í•­",37.523,126.592],
    ["TW_0089","ê²½í¬ëŒ€í•´ìˆ˜ìš•ì¥",37.808,128.931],
    ["TW_0095","ê³ ë˜ë¶ˆí•´ìˆ˜ìš•ì¥",36.58,129.454],
    ["TW_0074","ê´‘ì–‘í•­",34.859,127.792],
    ["TW_0072","êµ°ì‚°í•­",35.984,126.508],
    ["TW_0091","ë‚™ì‚°í•´ìˆ˜ìš•ì¥",38.122,128.65],
    ["KG_0025","ë‚¨í•´ë™ë¶€",34.222,128.419],
    ["TW_0069","ëŒ€ì²œí•´ìˆ˜ìš•ì¥",36.274,126.457],
    ["KG_0024","ëŒ€í•œí•´í˜‘",34.919,129.121],
    ["TW_0085","ë§ˆì‚°í•­",35.103,128.631],
    ["TW_0094","ë§ìƒí•´ìˆ˜ìš•ì¥",37.616,129.103],
    ["TW_0087","ë¶€ì‚°í•­",35.091,129.085],
    ["TW_0086","ë¶€ì‚°í•­ì‹ í•­",35.043,128.761],
    ["TW_0079","ìƒì™•ë“±ë„",35.652,126.194],
    ["TW_0081","ìƒì¼ë„",34.258,126.96],
    ["TW_0093","ì†ì´ˆí•´ìˆ˜ìš•ì¥",38.198,128.631],
    ["TW_0090","ì†¡ì •í•´ìˆ˜ìš•ì¥",35.164,129.219],
    ["TW_0083","ì—¬ìˆ˜í•­",34.794,127.808],
    ["TW_0078","ì™„ë„í•­",34.325,126.763],
    ["TW_0080","ìš°ì´ë„",34.543,125.802],
    ["KG_0101","ìš¸ë¦‰ë„ë¶ë™",38.007,131.552],
    ["KG_0102","ìš¸ë¦‰ë„ë¶ì„œ",37.742,130.601],
    ["TW_0076","ì¸ì²œí•­",37.389,126.533],
    ["TW_0092","ì„ë‘í•´ìˆ˜ìš•ì¥",35.302,129.292],
    ["KG_0021","ì œì£¼ë‚¨ë¶€",32.09,126.965],
    ["KG_0028","ì œì£¼í•´í˜‘",33.7,126.59],
    ["TW_0075","ì¤‘ë¬¸í•´ìˆ˜ìš•ì¥",33.234,126.409],
    ["TW_0082","íƒœì•ˆí•­",37.006,126.27],
    ["TW_0084","í†µì˜í•­",34.773,128.46],
    ["TW_0062","í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥",35.148,129.17]
]
data2 = [
    ["HF_0064","ê´‘ì–‘í•­",34.887,127.797],
    ["HF_0076","êµ°ì‚°í•­",35.99,126.358],
    ["HF_0041","ëŒ€í•œí•´í˜‘",34.909,129.2],
    ["HF_0073","ë™í•´ë‚¨ë¶€",36.633,130.224],
    ["HF_0075","ëª©í¬í•­ë‚´ì¸¡",34.756,126.336],
    ["HF_0074","ëª©í¬í•­ì™¸ì¸¡",34.772,126.239],
    ["HF_0040","ë¶€ì‚°í•­ì‹ í•­",35.036,128.768],
    ["HF_0065","ì—¬ìˆ˜ê´‘ì–‘í•­",34.765,127.804],
    ["HF_0039","ì—¬ìˆ˜í•´ë§Œ",34.656,127.964],
    ["HF_0063","ìš¸ì‚°í•­",35.4,129.607],
    ["HF_0069","ì¸ì²œí•­",37.355,126.508],
    ["HF_0070","íƒœì•ˆëŒ€ì‚°",37.073,126.292],
    ["HF_0071","í¬í•­í•­",36.066,129.475]
]




# ë°ì´í„° í•„í„°ë§ ë° STATIONS ë”•ì…”ë„ˆë¦¬ ìƒì„±
STATIONS1 = {}
for item in data1:
    # item: [ID, Name, Latitude (Y), Longitude (X)]
    station_id, name, lat, lon = item[0], item[1], item[2], item[3]

    # ê²½ë„ (lon)ì™€ ìœ„ë„ (lat)ê°€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
    is_in_x_range = MIN_X <= lon <= MAX_X
    is_in_y_range = MIN_Y <= lat <= MAX_Y
    
    if is_in_x_range and is_in_y_range:
        STATIONS1[station_id] = {
            'name': name,
            'lat': lat,
            'lon': lon
        }


# ë°ì´í„° í•„í„°ë§ ë° STATIONS ë”•ì…”ë„ˆë¦¬ ìƒì„±
STATIONS2 = {}
for item in data2:
    # item: [ID, Name, Latitude (Y), Longitude (X)]
    station_id, name, lat, lon = item[0], item[1], item[2], item[3]

    # ê²½ë„ (lon)ì™€ ìœ„ë„ (lat)ê°€ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
    is_in_x_range = MIN_X <= lon <= MAX_X
    is_in_y_range = MIN_Y <= lat <= MAX_Y
    
    if is_in_x_range and is_in_y_range:
        STATIONS2[station_id] = {
            'name': name,
            'lat': lat,
            'lon': lon
        }


from datetime import datetime, timedelta

# ==============================================================================
# ì„¤ì • ë¶€ë¶„ // ìœ„ê²½ë„ì— ë§ê²Œ ë²”ìœ„ ë‚´ì— ìˆëŠ” ê´€ì¸¡ì†Œì™€ í•´ìƒë¶€ì´ api ëŒê³ ì˜¤ê¸°
# ==============================================================================


# API ê¸°ë³¸ URL
BASE_URL = "http://www.khoa.go.kr/api/oceangrid/tidalBu/search.do"


# ìµœì¢… ì €ì¥ë  NetCDF íŒŒì¼ ì´ë¦„
khoa_buoy_OUTPUT_FILENAME = "khoa_buoy_data_20211101-20211102.nc"


# ==============================================================================
# í•´ìƒë¶€ìœ„ ë¡œì§
# ==============================================================================

if os.path.exists(khoa_buoy_OUTPUT_FILENAME):
    print(f"ğŸ”„ ì´ë¯¸ NetCDF íŒŒì¼ì´ ì¡´ì¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ìƒëµí•©ë‹ˆë‹¤: {khoa_buoy_OUTPUT_FILENAME}")
else:
    all_records = []
    
    # APIëŠ” í•˜ë£¨ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ì œê³µí•˜ë¯€ë¡œ, ë‚ ì§œ ëª©ë¡ ìƒì„±
    date_list = pd.date_range(start=START_DATE.date(), end=END_DATE.date()).tolist()

    # ====== API í˜¸ì¶œ ë° ë°ì´í„° ìˆ˜ì§‘ ======
    for station_id, station_info in STATIONS1.items():
        for search_date in date_list:
            print(f"ğŸ“¡ {station_info['name']}({station_id}) ê´€ì¸¡ì†Œì˜ {search_date.strftime('%Y-%m-%d')} ë°ì´í„° ìš”ì²­ ì¤‘...")
            
            params = {
                'ServiceKey': SERVICE_KEY,
                'ObsCode': station_id,
                'Date': search_date.strftime('%Y%m%d'),
                'ResultType': 'json'
            }
            
            try:
                response = requests.get(BASE_URL, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    # ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if 'result' in data and 'data' in data['result']:
                        for record in data['result']['data']:
                            all_records.append({
                                'station_id': station_id,
                                'station_name': station_info['name'],
                                'lat': station_info['lat'],
                                'lon': station_info['lon'],
                                'time': pd.to_datetime(record['obs_time']),
                                'current_speed_cm_s': pd.to_numeric(record['current_speed'], errors='coerce'),
                                'current_direction_deg': pd.to_numeric(record['current_direct'], errors='coerce')
                            })
                    else:
                        print(f"   âš ï¸ ë°ì´í„° ì—†ìŒ: {station_info['name']} ({search_date.strftime('%Y-%m-%d')})")

                else:
                    print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {station_info['name']}, Status Code: {response.status_code}")

            except requests.exceptions.RequestException as e:
                print(f"   âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {station_info['name']}, {e}")
            except Exception as e:
                print(f"   âŒ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {station_info['name']}, {e}")
    
    if not all_records:
        print("ğŸ˜­ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ NetCDF íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ====== ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë° í•„í„°ë§ ======
        df = pd.DataFrame(all_records)
        df.dropna(inplace=True) # ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°

        # ì‹œê°„ ë²”ìœ„ ë° ì •ê° ë°ì´í„° í•„í„°ë§
        df_hourly = df[
            (df['time'] >= START_DATE) & 
            (df['time'] <= END_DATE) & 
            (df['time'].dt.minute == 0)
        ].copy()

        print(f"\nğŸ“Š ì´ {len(df_hourly)}ê°œì˜ ì‹œê°„ë³„ ê´€ì¸¡ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.")

        # ====== NetCDF ìƒì„± ======
        # xarrayê°€ ì¸ì‹í•˜ê¸° ì¢‹ê²Œ station_idë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        df_hourly.drop_duplicates(subset=['station_id', 'time'], inplace=True, keep='first')

        # ì´ì œ ì¤‘ë³µì´ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        df_hourly.set_index(['station_id', 'time'], inplace=True)
        ds = df_hourly.to_xarray()
        
        # ê° ë³€ìˆ˜ì— ëŒ€í•œ ì†ì„±(ì„¤ëª…, ë‹¨ìœ„) ì¶”ê°€
        ds['station_name'].attrs = {'long_name': 'Observation station name'}
        ds['lat'].attrs = {'long_name': 'Latitude', 'units': 'degrees_north'}
        ds['lon'].attrs = {'long_name': 'Longitude', 'units': 'degrees_east'}
        ds['current_speed_cm_s'].attrs = {'long_name': 'Sea water speed', 'units': 'cm/s'}
        ds['current_direction_deg'].attrs = {'long_name': 'Sea water direction (from north)', 'units': 'degree'}

        # íŒŒì¼ ì „ì²´ì— ëŒ€í•œ ì „ì—­ ì†ì„± ì¶”ê°€
        ds.attrs = {
            'title': 'KHOA Oceanographic Buoy Data',
            'source': 'Korea Hydrographic and Oceanographic Agency (KHOA)',
            'api': 'tidalBu (í•´ì–‘ê´€ì¸¡ë¶€ì´)',
            'description': 'Hourly current speed and direction data from KHOA buoys.',
            'history': f'Created on {datetime.now().isoformat()}'
        }
        
        # NetCDF íŒŒì¼ë¡œ ì €ì¥
        ds.to_netcdf(khoa_buoy_OUTPUT_FILENAME)
        print(f"\nâœ… NetCDF íŒŒì¼ ìƒì„± ì™„ë£Œ: {khoa_buoy_OUTPUT_FILENAME}")
        
        
# ==============================================================================
# í•´ìƒ ê´€ì¸¡ì†Œ ë¡œì§
# ==============================================================================        
        
# HF-RADAR API ê¸°ë³¸ ì •ë³´
BASE_URL = "http://www.khoa.go.kr/api/oceangrid/tidalHfRadar/search.do"

# ë°ì´í„° ì¡°íšŒ ê¸°ê°„ ì„¤ì • (ì´ì „ê³¼ ë™ì¼)
start_date = datetime(2021, 11, 1, 0, 0)
end_date = datetime(2021, 11, 2, 23, 0)
time_list = pd.date_range(start=start_date, end=end_date, freq='H')

# ìµœì¢… ì €ì¥ë  NetCDF íŒŒì¼ ì´ë¦„
KHOA_HFRadar_output_path = f"KHOA_HFRadar_data_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.nc"


# ==================================
# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬
# ==================================
if os.path.exists(KHOA_HFRadar_output_path):
    print(f"ğŸ”„ ì´ë¯¸ NetCDF íŒŒì¼ì´ ì¡´ì¬í•˜ì—¬ ë‹¤ìš´ë¡œë“œë¥¼ ìƒëµí•©ë‹ˆë‹¤: {KHOA_HFRadar_output_path}")
else:
    all_records = []

    print("ğŸš€ HF-RADAR API ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    # ëª¨ë“  ê´€ì¸¡ì†Œì™€ ì‹œê°„ì— ëŒ€í•´ API í˜¸ì¶œ
    for obs_code, station_name in STATIONS2.items():
        for t in time_list:
            # Date íŒŒë¼ë¯¸í„° í˜•ì‹ì´ YYYYMMDDHH ì…ë‹ˆë‹¤.
            date_str = t.strftime("%Y%m%d%H")
            
            params = {
                'ServiceKey': SERVICE_KEY,
                'ObsCode': obs_code,
                'Date': date_str,
                'ResultType': 'json'
            }
            
            try:
                response = requests.get(BASE_URL, params=params)
                if response.status_code == 200:
                    data = response.json()
                    # 'data' í‚¤ê°€ ìˆëŠ”ì§€, ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                    if 'result' in data and 'data' in data['result'] and data['result']['data']:
                        # í•œ ë²ˆì˜ í˜¸ì¶œë¡œ ì—¬ëŸ¬ ìœ„ì¹˜ì˜ ë°ì´í„°ê°€ ë“¤ì–´ì˜´
                        for record in data['result']['data']:
                            all_records.append({
                                'time': t,
                                'station_id': obs_code,
                                'station_name': station_name,
                                'lat': float(record.get('lat', float('nan'))),
                                'lon': float(record.get('lon', float('nan'))),
                                'current_speed': float(record.get('current_speed', float('nan'))), # cm/s
                                'current_direct': float(record.get('current_direct', float('nan'))) # deg
                            })
                        print(f"âœ… [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
                    else:
                        print(f"âš ï¸ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} API í˜¸ì¶œ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            except requests.exceptions.RequestException as e:
                print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} ìš”ì²­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            except ValueError: # JSON ë””ì½”ë”© ì˜¤ë¥˜ ì²˜ë¦¬
                 print(f"âŒ [{station_name}({obs_code})] {t.strftime('%Y-%m-%d %H:%M')} JSON íŒŒì‹± ì‹¤íŒ¨. ì‘ë‹µ ë‚´ìš©: {response.text}")


    if not all_records:
        print("ğŸ˜­ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ NetCDF íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ==================================
        # 3. NetCDF ìƒì„±
        # ==================================
        print("\nğŸ“Š NetCDF íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        df = pd.DataFrame(all_records)
        # ì¤‘ë³µ ë°ì´í„° ì œê±° (ì•ˆì •ì„± í™•ë³´)
        df.drop_duplicates(subset=['time', 'lat', 'lon'], inplace=True, keep='first')
        
        # ë°ì´í„°í”„ë ˆì„ì„ xarray Datasetìœ¼ë¡œ ë³€í™˜
        # HF-Radar ë°ì´í„°ëŠ” ê° ì‹œê°„ì´ ê³µê°„ ê²©ìë¥¼ ê°€ì§€ë¯€ë¡œ, ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
        ds = df.set_index('time').to_xarray()
        
        # ë³€ìˆ˜ ì†ì„±(metadata) ì¶”ê°€
        ds['current_speed'].attrs = {'long_name': 'Sea Water Speed', 'units': 'cm/s'}
        ds['current_direct'].attrs = {'long_name': 'Sea Water To Direction', 'units': 'degree'}
        ds['lat'].attrs = {'units': 'degrees_north'}
        ds['lon'].attrs = {'units': 'degrees_east'}
        ds['station_id'].attrs = {'long_name': 'Observation station code'}
        
        # ì „ì—­ ì†ì„±(Global attributes) ì¶”ê°€
        ds.attrs = {
            'title': 'KHOA HF-RADAR Ocean Current Data',
            'source': 'Korea Hydrographic and Oceanographic Agency (KHOA)',
            'api_url': 'http://www.khoa.go.kr/api/oceangrid/tidalHfRadar/search.do',
            'history': f'Created on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        }

        # NetCDF íŒŒì¼ë¡œ ì €ì¥
        ds.to_netcdf(KHOA_HFRadar_output_path)
        print(f"âœ… NetCDF ìƒì„± ì™„ë£Œ: {KHOA_HFRadar_output_path}")
        
        
        
# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================
# ================================================================================================================================
# OI ìµœì  ë‚´ì‚½ë²• ì ìš©
        

from scipy.spatial import cKDTree
from math import radians, sin, cos, sqrt, atan2

# ===================================================================
# 1. ì„¤ì • (Configuration)
# ===================================================================

# --- ì…ë ¥ íŒŒì¼ ê²½ë¡œ ---
# 1. ë°°ê²½ ëª¨ë¸ ë°ì´í„° (HYCOM + KHOA, ê²©ì í˜•íƒœ)
BACKGROUND_NC_FILE = r'.combined_currents.nc' 
# 2. í•´ìƒ ë¶€ì´ ê´€ì¸¡ ë°ì´í„° (ì´ì „ì— ìƒì„±í•œ íŒŒì¼)
BUOY_NC_FILE = khoa_buoy_OUTPUT_FILENAME
# 3. HF-Radar ê´€ì¸¡ ë°ì´í„° (ì´ì „ì— ìƒì„±í•œ íŒŒì¼)
RADAR_NC_FILE = KHOA_HFRadar_output_path

# --- ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ---
OUTPUT_NC_FILE = 'assimilated_ocean_current.nc'

# --- ìë£Œ ë™í™” ì£¼ìš” íŒŒë¼ë¯¸í„° ---
# ì˜í–¥ ë°˜ê²½ (ë‹¨ìœ„: km): í•˜ë‚˜ì˜ ê´€ì¸¡ê°’ì´ ì£¼ë³€ ëª‡ kmê¹Œì§€ ì˜í–¥ì„ ë¯¸ì¹ ì§€ ê²°ì •í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜
# (ì‹¤í—˜ì„ í†µí•´ ì ì ˆí•œ ê°’ì„ ì°¾ì•„ì•¼ í•¨, ë³´í†µ 10~50km ì‚¬ì´ì—ì„œ ì‹œì‘)
INFLUENCE_RADIUS_KM = 20.0

# ===================================================================
# 2. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# ===================================================================

print("ğŸ”„ 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

# --- ë°ì´í„° ë¡œë”© ---
ds_bg = xr.open_dataset(BACKGROUND_NC_FILE)
ds_buoy = xr.open_dataset(BUOY_NC_FILE)
ds_radar = xr.open_dataset(RADAR_NC_FILE)

# --- ê´€ì¸¡ ë°ì´í„° í†µí•© ---
# xarray Datasetì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
df_buoy = ds_buoy.to_dataframe().reset_index()
df_radar = ds_radar.to_dataframe().reset_index()
df_obs = pd.concat([df_buoy, df_radar], ignore_index=True)

# --- ê´€ì¸¡ ë°ì´í„° í˜•ì‹ í†µì¼ (u, v ì„±ë¶„ìœ¼ë¡œ ë³€í™˜) ---
# ìœ ì†(cm/s) -> m/së¡œ ë³€í™˜
df_obs['current_speed_mps'] = df_obs['current_speed'] / 100.0
# ìœ í–¥(degree) -> radianìœ¼ë¡œ ë³€í™˜
df_obs['direction_rad'] = np.deg2rad(df_obs['current_direct'])

# u(ë™-ì„œ), v(ë‚¨-ë¶) ì„±ë¶„ ê³„ì‚° (ê¸°ìƒ/í•´ì–‘í•™ í‘œì¤€)
# u = speed * sin(direction)
# v = speed * cos(direction)
df_obs['u_obs'] = df_obs['current_speed_mps'] * np.sin(df_obs['direction_rad'])
df_obs['v_obs'] = df_obs['current_speed_mps'] * np.cos(df_obs['direction_rad'])

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ ë° ê²°ì¸¡ì¹˜ ì œê±°
df_obs = df_obs[['time', 'lat', 'lon', 'u_obs', 'v_obs']].dropna()

# ğŸ’¡ í•´ê²°: try-except êµ¬ë¬¸ìœ¼ë¡œ ì‹œê°„ëŒ€ ì •ë³´ ì¡´ì¬ ì—¬ë¶€ë¥¼ ë” ì•ˆì •ì ìœ¼ë¡œ í™•ì¸
try:
    # ds_bgì˜ ì‹œê°„ëŒ€ ì •ë³´ë¥¼ í™•ì¸í•˜ë ¤ëŠ” ì‹œë„
    target_tz = ds_bg.time.dt.tz
    print(f"ë°°ê²½ ë°ì´í„°ì˜ ì‹œê°„ëŒ€({target_tz})ì— ë§ì¶° ê´€ì¸¡ ë°ì´í„°ì˜ ì‹œê°„ëŒ€ë¥¼ í†µì¼í•©ë‹ˆë‹¤.")
    # ì„±ê³µí•˜ë©´ (ì‹œê°„ëŒ€ ì •ë³´ê°€ ìˆìœ¼ë©´) df_obsì˜ ì‹œê°„ëŒ€ë¥¼ í†µì¼
    if df_obs['time'].dt.tz is None:
        df_obs['time'] = df_obs['time'].dt.tz_localize('UTC').dt.tz_convert(target_tz)
    else:
        df_obs['time'] = df_obs['time'].dt.tz_convert(target_tz)
        
except AttributeError:
    # AttributeErrorê°€ ë°œìƒí•˜ë©´ ds_bgì— ì‹œê°„ëŒ€ ì •ë³´ê°€ ì—†ëŠ” ê²ƒì´ë¯€ë¡œ
    print("ë°°ê²½ ë°ì´í„°ì— ì‹œê°„ëŒ€ ì •ë³´ê°€ ì—†ì–´ ê´€ì¸¡ ë°ì´í„°ì˜ ì‹œê°„ëŒ€ ì •ë³´ë„ ì œê±°í•©ë‹ˆë‹¤.")
    df_obs['time'] = df_obs['time'].dt.tz_localize(None)


# ===================================================================
# 3. ìë£Œ ë™í™” ìˆ˜í–‰ (Optimal Interpolation)
# ===================================================================
print(f"ğŸš€ 2. ìë£Œ ë™í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤... (ì˜í–¥ ë°˜ê²½: {INFLUENCE_RADIUS_KM}km)")

# --- ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ìƒˆë¡œìš´ ë³€ìˆ˜ ìƒì„± (ë°°ê²½ì¥ ë³µì‚¬) ---
# u, v ë³€ìˆ˜ëª…ì´ ë‹¤ë¥¼ ê²½ìš° ì•„ë˜ 'eastward_velocity', 'northward_velocity'ë¥¼ ì‹¤ì œ ë³€ìˆ˜ëª…ìœ¼ë¡œ ìˆ˜ì •
u_an = ds_bg['eastward_velocity'].copy(deep=True) 
v_an = ds_bg['northward_velocity'].copy(deep=True)

# --- ê²©ìì  ì¢Œí‘œ ì¤€ë¹„ ---
# ê²½ë„(lon), ìœ„ë„(lat) ì¢Œí‘œë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
lons = ds_bg.lon.values
lats = ds_bg.lat.values
lon_grid, lat_grid = np.meshgrid(lons, lats)
grid_points = np.vstack([lon_grid.ravel(), lat_grid.ravel()]).T

# --- ê³µê°„ ê²€ìƒ‰ì„ ìœ„í•œ KD-Tree ìƒì„± ---
# íŠ¹ì • ìœ„ì¹˜ì—ì„œ ê°€ê¹Œìš´ ê²©ìì ì„ ë¹ ë¥´ê²Œ ì°¾ê¸° ìœ„í•¨
kdtree = cKDTree(grid_points)

# --- ì‹œê°„ë³„ ë£¨í”„ ì‹¤í–‰ ---
for t_idx, current_time in enumerate(ds_bg.time.values):
    print(f"  - ì‹œê°„ ì²˜ë¦¬ ì¤‘: {str(current_time)}")
    
    # í˜„ì¬ ì‹œê°„ê³¼ ì¼ì¹˜í•˜ëŠ” ê´€ì¸¡ ë°ì´í„° í•„í„°ë§
    obs_t = df_obs[df_obs['time'] == current_time]
    
    if len(obs_t) == 0:
        continue # í˜„ì¬ ì‹œê°„ì— ê´€ì¸¡ê°’ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ ì‹œê°„ìœ¼ë¡œ
        
    # ë°°ê²½ì¥ u, v ê°’ (ë¶„ì„ì¥ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë³µì‚¬)
    u_bg_t = ds_bg['eastward_velocity'][t_idx].values
    v_bg_t = ds_bg['northward_velocity'][t_idx].values
    
    u_an_t = u_an[t_idx].values
    v_an_t = v_an[t_idx].values
    
    # ê° ê²©ìì ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ í•©ê³¼ í˜ì‹ (innovation) í•©ì„ ì €ì¥í•  ë°°ì—´
    total_weights = np.zeros_like(u_bg_t)
    total_u_update = np.zeros_like(u_bg_t)
    total_v_update = np.zeros_like(u_bg_t)

    # ê° ê´€ì¸¡ê°’ì— ëŒ€í•´ ì˜í–¥ ê³„ì‚°
    for _, obs in obs_t.iterrows():
        obs_point = np.array([obs['lon'], obs['lat']])
        
        # ë°°ê²½ì¥ ê°’ì„ ê´€ì¸¡ ìœ„ì¹˜ë¡œ ë³´ê°„ (ê°€ì¥ ê°€ê¹Œìš´ ê²©ìì  ê°’ ì‚¬ìš©)
        dist, idx = kdtree.query(obs_point)
        bg_point_flat_idx = idx
        bg_point_coords = np.unravel_index(bg_point_flat_idx, u_bg_t.shape)
        
        u_bg_at_obs = u_bg_t[bg_point_coords]
        v_bg_at_obs = v_bg_t[bg_point_coords]

        # í˜ì‹  (Innovation) ê³„ì‚°: ê´€ì¸¡ê°’ê³¼ ë°°ê²½ì¥ì˜ ì°¨ì´
        u_innov = obs['u_obs'] - u_bg_at_obs
        v_innov = obs['v_obs'] - v_bg_at_obs
        
        # ì˜í–¥ ë°˜ê²½ ë‚´ì˜ ëª¨ë“  ê²©ìì  ì°¾ê¸° (ë‹¨ìœ„: degree)
        # ìœ„ë„ 1ë„ëŠ” ì•½ 111km
        radius_deg = INFLUENCE_RADIUS_KM / 111.0 
        nearby_indices = kdtree.query_ball_point(obs_point, r=radius_deg)
        
        if not nearby_indices:
            continue
            
        nearby_grid_points = grid_points[nearby_indices]
        
        # ê´€ì¸¡ì ê³¼ ì£¼ë³€ ê²©ìì ë“¤ ê°„ì˜ ê±°ë¦¬ ê³„ì‚° (Haversine ê³µì‹ ëŒ€ì‹  ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¡œ ê·¼ì‚¬)
        distances_sq = np.sum((nearby_grid_points - obs_point)**2, axis=1)
        
        # ê°€ì¤‘ì¹˜ ê³„ì‚° (Gaussian weight)
        L = radius_deg  # ì˜í–¥ ë°˜ê²½ì„ í‘œì¤€í¸ì°¨ì²˜ëŸ¼ ì‚¬ìš©
        weights = np.exp(-0.5 * distances_sq / (L**2))
        
        # ê° ì£¼ë³€ ê²©ìì ì˜ ì¸ë±ìŠ¤ë¥¼ 2Dë¡œ ë³€í™˜
        nearby_coords_2d = np.unravel_index(nearby_indices, u_bg_t.shape)
        
        # ê°€ì¤‘ì¹˜ì™€ í˜ì‹ ì„ ëˆ„ì 
        total_weights[nearby_coords_2d] += weights
        total_u_update[nearby_coords_2d] += u_innov * weights
        total_v_update[nearby_coords_2d] += v_innov * weights

    # ëˆ„ì ëœ ê°€ì¤‘ì¹˜ë¡œ ì—…ë°ì´íŠ¸ ê°’ ì •ê·œí™”
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€
    mask = total_weights > 0
    u_an_t[mask] += total_u_update[mask] / total_weights[mask]
    v_an_t[mask] += total_v_update[mask] / total_weights[mask]
    
    # ìµœì¢… ë¶„ì„ì¥ì„ ì—…ë°ì´íŠ¸
    u_an[t_idx] = u_an_t
    v_an[t_idx] = v_an_t


# ===================================================================
# 4. ê²°ê³¼ ì €ì¥
# ===================================================================
print(f"ğŸ’¾ 3. ë™í™”ëœ ê²°ê³¼ë¥¼ NetCDF íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤: {OUTPUT_NC_FILE}")

# ì›ë³¸ ë°ì´í„°ì…‹ì— ë¶„ì„ì¥ì„ ìƒˆë¡œìš´ ë³€ìˆ˜ë¡œ ì¶”ê°€
ds_assimilated = ds_bg.copy()
ds_assimilated['u_assimilated'] = u_an
ds_assimilated['v_assimilated'] = v_an
ds_assimilated['u_assimilated'].attrs = {'long_name': 'Assimilated eastward sea water velocity', 'units': 'm/s'}
ds_assimilated['v_assimilated'].attrs = {'long_name': 'Assimilated northward sea water velocity', 'units': 'm/s'}

# íŒŒì¼ë¡œ ì €ì¥
ds_assimilated.to_netcdf(OUTPUT_NC_FILE)

print("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        
        
        